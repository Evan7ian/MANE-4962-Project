{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e758c51",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39df8bc",
   "metadata": {},
   "source": [
    "Diversity: The dataset should represent a diverse population in terms of age, gender, race, and socio-economic background. This will allow the models to consider variations in mental health disorders and treatment responses across different population groups.\n",
    "\n",
    "Mental Health Diagnoses: The dataset should include patients with various mental health disorders (e.g., depression, anxiety, bipolar disorder, schizophrenia) to capture the complexity and heterogeneity of these conditions.\n",
    "\n",
    "Demographic Information: The dataset should include demographic features such as age, gender, race, education level, marital status, and socio-economic status.\n",
    "\n",
    "Mental Health History: The dataset should contain information about patients' mental health history, including previous diagnoses, symptom severity, duration of illness, comorbidities, and family history of mental health disorders.\n",
    "\n",
    "Treatment History: The dataset should provide comprehensive information on patients' treatment history, including types of treatments (e.g., psychotherapy, medication, electroconvulsive therapy), medications used, dosages, treatment adherence, and treatment outcomes.\n",
    "\n",
    "--Lifestyle Factors: The dataset should include information on lifestyle factors that may influence mental health and treatment response, such as sleep patterns, physical activity, diet, substance use, and social support.\n",
    "\n",
    "--Genetic Information: The dataset should include genetic information, such as single nucleotide polymorphisms (SNPs) or other genetic variations associated with mental health disorders or treatment response, if available."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6f4615",
   "metadata": {},
   "source": [
    "Selected features:\n",
    "\n",
    "AGE: Age at admission\n",
    "\n",
    "DSMCRIT: DSM diagnosis (SuDS 4 or SuDS 19) \n",
    "\n",
    "Client's diagnosis is used to identify the substance use problem that provides the reason for client encounter or treatment. This can be reported by using either the Diagnostic and Statistical Manual of Mental Disorders (DSM) from the American Psychiatric Association or the International Classification of Diseases (ICD), from the World Health Organization. \n",
    "\n",
    "The discrete diagnosis codes have been recoded into categories related to use of and dependence on specific substances, mental health conditions, and other conditions. Diagnoses reported by states using either standard classification of mental disorders have been combined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211878fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71c2ab3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "\n",
    "data_dis18 = pd.read_csv('tedsd_puf_2018.csv')\n",
    "data_dis19 = pd.read_csv('tedsd_puf_2019.csv')\n",
    "data_dis20 = pd.read_csv('tedsd_puf_2020.csv')\n",
    "\n",
    "data_dis = pd.concat([data_dis18, data_dis19, data_dis20], axis=0, ignore_index=True)\n",
    "\n",
    "filtered_dis = data_dis[data_dis['NOPRIOR'] == 0] # Filter No Previous substance use treatment episodes\n",
    "filtered_dis = filtered_dis[filtered_dis['RACE'] == 6] # Filter Asian\n",
    "filtered_dis = filtered_dis[filtered_dis['SERVICES'] == 7] # Filter \n",
    "filtered_dis = filtered_dis.dropna()  # Drop missing values\n",
    "data_final = filtered_dis[['MARSTAT','EMPLOY_D','EDUC','PRIMINC','HLTHINS', \n",
    "                           'SUB1','LOS','FREQ1','FREQ1_D','PSYPROB','FRSTUSE1','ROUTE1','REASON',\n",
    "                           'DSMCRIT',]]\n",
    "\n",
    "X = data_final.drop('DSMCRIT', axis=1)  # Remove target variable from input features\n",
    "y = data_final['DSMCRIT']  # Target variable\n",
    "\n",
    "# X = filtered_dis.drop('DSMCRIT', axis=1)  # Remove target variable from input features ALL\n",
    "# y = filtered_dis['DSMCRIT']  # Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fe0d2e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=123) # Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3ebf12b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6191, 13)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cbecc1",
   "metadata": {},
   "source": [
    "## RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "13350fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MARSTAT</td>\n",
       "      <td>0.133845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LOS</td>\n",
       "      <td>0.118500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SUB1</td>\n",
       "      <td>0.101477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PRIMINC</td>\n",
       "      <td>0.100657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HLTHINS</td>\n",
       "      <td>0.082276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>FRSTUSE1</td>\n",
       "      <td>0.077790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EDUC</td>\n",
       "      <td>0.076414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EMPLOY_D</td>\n",
       "      <td>0.059554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>REASON</td>\n",
       "      <td>0.055229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PSYPROB</td>\n",
       "      <td>0.050751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FREQ1_D</td>\n",
       "      <td>0.050022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>ROUTE1</td>\n",
       "      <td>0.048146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>FREQ1</td>\n",
       "      <td>0.045339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "0    MARSTAT    0.133845\n",
       "6        LOS    0.118500\n",
       "5       SUB1    0.101477\n",
       "3    PRIMINC    0.100657\n",
       "4    HLTHINS    0.082276\n",
       "10  FRSTUSE1    0.077790\n",
       "2       EDUC    0.076414\n",
       "1   EMPLOY_D    0.059554\n",
       "12    REASON    0.055229\n",
       "9    PSYPROB    0.050751\n",
       "8    FREQ1_D    0.050022\n",
       "11    ROUTE1    0.048146\n",
       "7      FREQ1    0.045339"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "column_names = data_final.columns\n",
    "column_names\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500)\n",
    "rnd_clf.fit(X, y)\n",
    "\n",
    "feature_importances = rnd_clf.feature_importances_\n",
    "importances_df = pd.DataFrame({'feature': X.columns, 'importance': feature_importances})\n",
    "importances_df = importances_df.sort_values('importance', ascending=False)\n",
    "importances_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7165d6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 31.7783\n",
      "R^2 Score: 0.6570\n"
     ]
    }
   ],
   "source": [
    "regr = RandomForestRegressor(max_depth=3)\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "print(f\"R^2 Score: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1f5293cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class AUC: 0.9110814133522204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "y_pred_rf = rnd_clf.predict(X_test)\n",
    "\n",
    "y_pred_proba = rnd_clf.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "print(f\"Multi-class AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6243de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(max_leaf_nodes=16, n_jobs=-1,\n",
       "                                              random_state=123),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 10], 'n_estimators': [500]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Train the model\n",
    "clf = RandomForestClassifier(random_state=123, max_leaf_nodes=16, n_jobs=-1)\n",
    "params = {'n_estimators': [500],\n",
    "          'max_depth': [5,10],}\n",
    "grid_search = GridSearchCV(clf, param_grid=params, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "73616886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6273549359457423\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -9       0.80      0.91      0.85      1251\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.00      0.00      0.00        32\n",
      "           3       0.00      0.00      0.00        15\n",
      "           4       0.50      0.01      0.03       219\n",
      "           5       0.62      0.28      0.39       124\n",
      "           6       0.00      0.00      0.00        27\n",
      "           7       0.41      0.19      0.26       137\n",
      "           8       0.42      0.83      0.56       150\n",
      "           9       0.40      0.45      0.42       247\n",
      "          10       0.41      0.50      0.45       154\n",
      "          11       0.00      0.00      0.00        39\n",
      "          12       0.00      0.00      0.00        14\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          19       0.43      0.71      0.54       211\n",
      "\n",
      "    accuracy                           0.63      2654\n",
      "   macro avg       0.21      0.20      0.18      2654\n",
      "weighted avg       0.59      0.63      0.58      2654\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6b47e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1115    0    0    2   23   17    2   14   10   28   26    1    0    1\n",
      "     0    0    0    0   12]\n",
      " [   6    0    0    0    3    2    0    2    0    6    0    0    0    0\n",
      "     0    0    0    0    1]\n",
      " [   5    0    6    0    1    2    1    3    8    0    4    0    0    0\n",
      "     0    0    0    0    2]\n",
      " [   0    0    0    4    2    1    0    0    2    5    0    0    0    0\n",
      "     0    0    0    0    1]\n",
      " [  23    0    2    2   49    6    3    4   10   63    1    1    0    0\n",
      "     0    0    0    0   55]\n",
      " [  20    0    0    0    1   57    1    8   21    3    4    2    1    0\n",
      "     0    0    0    0    6]\n",
      " [   5    0    1    0    3    4    7    0    1    1    0    0    0    1\n",
      "     0    0    0    0    4]\n",
      " [  17    0    0    0    2    5    0   59    5    4   28    0    0    0\n",
      "     0    0    0    0   17]\n",
      " [   4    0    0    0    4   11    0    0  109    3    5   10    0    0\n",
      "     0    0    0    0    4]\n",
      " [  25    0    1    5   43    5    2    3    7   92    5    0    0    0\n",
      "     0    0    0    0   59]\n",
      " [  20    0    0    1    3   11    2   22    1    5   76    0    0    0\n",
      "     0    0    0    0   13]\n",
      " [   1    0    0    0    0    3    1    1   23    0    1    6    0    0\n",
      "     0    0    0    0    3]\n",
      " [   1    0    0    0    0    5    0    1    4    0    1    0    0    0\n",
      "     0    0    0    0    2]\n",
      " [   4    0    0    0    0    0    3    1    0    0    0    0    0    0\n",
      "     0    0    0    0    1]\n",
      " [   2    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   1    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0    0    0    0    0]\n",
      " [   4    0    0    0   23    8    3   17    8   20   12    4    0    0\n",
      "     0    0    0    0  112]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -9       0.89      0.89      0.89      1251\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.60      0.19      0.29        32\n",
      "           3       0.29      0.27      0.28        15\n",
      "           4       0.31      0.22      0.26       219\n",
      "           5       0.42      0.46      0.44       124\n",
      "           6       0.28      0.26      0.27        27\n",
      "           7       0.43      0.43      0.43       137\n",
      "           8       0.52      0.73      0.61       150\n",
      "           9       0.40      0.37      0.39       247\n",
      "          10       0.47      0.49      0.48       154\n",
      "          11       0.25      0.15      0.19        39\n",
      "          12       0.00      0.00      0.00        14\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          19       0.38      0.53      0.45       211\n",
      "\n",
      "    accuracy                           0.64      2654\n",
      "   macro avg       0.28      0.26      0.26      2654\n",
      "weighted avg       0.63      0.64      0.63      2654\n",
      "\n",
      "Accuracy: 63.75%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(100, ), \n",
    "    activation='relu', \n",
    "    solver='adam', \n",
    "    max_iter=300, \n",
    "    random_state=42)\n",
    "\n",
    "mlp.fit(X_train, y_train)\n",
    "y_pred = mlp.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "\n",
    "y_pred_proba = mlp.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "print(f\"Multi-class AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "529884e0",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7773c9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def ANN(input_dim, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "884a9d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 256)               3584      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44,801\n",
      "Trainable params: 44,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "87/87 [==============================] - 1s 7ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 2/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 3/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 4/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 5/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 6/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 7/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 8/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 9/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 10/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 11/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 12/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 13/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 14/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 15/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 16/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 17/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 18/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 19/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 20/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 21/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 22/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 23/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 24/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 25/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 26/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 27/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 28/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 29/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 30/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 31/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 32/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 33/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 34/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 35/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 36/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 37/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 38/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 39/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 40/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 41/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 42/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 43/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 44/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 45/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 46/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 47/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 48/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 50/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 51/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 52/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 53/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 54/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 55/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 56/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 57/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 58/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 59/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 60/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 61/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 62/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 63/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 64/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 65/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 66/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 67/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 68/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 69/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 70/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 71/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 72/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 73/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 74/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 75/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 76/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 77/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 78/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 79/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 80/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 81/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 82/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 83/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 84/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 85/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 86/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 87/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 88/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 89/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 90/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 91/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 92/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 93/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 94/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 95/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 96/100\n",
      "87/87 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 97/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 98/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 99/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "Epoch 100/100\n",
      "87/87 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0060 - val_loss: 0.0000e+00 - val_accuracy: 0.0097\n",
      "83/83 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0075\n",
      "Test accuracy: 0.0075357952155172825\n"
     ]
    }
   ],
   "source": [
    "input_dim = 13\n",
    "num_classes = 1\n",
    "\n",
    "ANN_model = ANN(input_dim, num_classes)\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "ANN_model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ANN_model.summary()\n",
    "history = ANN_model.fit(X_train, y_train, epochs=100, batch_size=50, validation_split=0.3)\n",
    "test_loss, test_acc = ANN_model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b91b47c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512db7fa",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "020f64f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-class AUC: 0.8618731654026116\n",
      "Accuracy:  0.573474001507159\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -9       0.76      0.86      0.81      1251\n",
      "           1       0.00      0.00      0.00        20\n",
      "           2       0.50      0.03      0.06        32\n",
      "           3       0.00      0.00      0.00        15\n",
      "           4       0.32      0.16      0.22       219\n",
      "           5       0.20      0.04      0.07       124\n",
      "           6       0.00      0.00      0.00        27\n",
      "           7       0.38      0.06      0.10       137\n",
      "           8       0.38      0.59      0.46       150\n",
      "           9       0.36      0.39      0.38       247\n",
      "          10       0.34      0.32      0.33       154\n",
      "          11       0.00      0.00      0.00        39\n",
      "          12       0.00      0.00      0.00        14\n",
      "          13       0.00      0.00      0.00         9\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         1\n",
      "          19       0.37      0.74      0.49       211\n",
      "\n",
      "    accuracy                           0.57      2654\n",
      "   macro avg       0.19      0.17      0.15      2654\n",
      "weighted avg       0.52      0.57      0.53      2654\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "classifier = LogisticRegression(multi_class='ovr')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_proba = classifier.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "print(f\"Multi-class AUC: {auc}\")\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c68b110",
   "metadata": {},
   "source": [
    "## SL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "df24631a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1092: RuntimeWarning: Number of classes in training fold (18) does not match total number of classes (19). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1092: RuntimeWarning: Number of classes in training fold (18) does not match total number of classes (19). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1092: RuntimeWarning: Number of classes in training fold (18) does not match total number of classes (19). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1092: RuntimeWarning: Number of classes in training fold (18) does not match total number of classes (19). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1092: RuntimeWarning: Number of classes in training fold (18) does not match total number of classes (19). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:1092: RuntimeWarning: Number of classes in training fold (18) does not match total number of classes (19). Results may not be appropriate for your use case. To fix this, use a cross-validation technique resulting in properly stratified folds\n",
      "  warnings.warn(\n",
      "C:\\Users\\qiany9\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Super Learner Accuracy: 0.6782215523737755\n",
      "Multi-class AUC: 0.9041912753914999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "base_models = [\n",
    "    ('random_forest', RandomForestClassifier(random_state=123)),\n",
    "    ('svm', SVC(probability=True)),\n",
    "    ('logistic_regression', LogisticRegression())\n",
    "]\n",
    "\n",
    "meta_model = LogisticRegression()\n",
    "\n",
    "stacking_classifier = StackingClassifier(estimators=base_models, final_estimator=meta_model)\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "y_pred = stacking_classifier.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Super Learner Accuracy: {accuracy}\")\n",
    "\n",
    "y_pred_proba = stacking_classifier.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')\n",
    "print(f\"Multi-class AUC: {auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77d5f40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
